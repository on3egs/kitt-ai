# ü§ñ KYRONEX ‚Äî SUPER NOTES COMPL√àTES
**Kinetic Yielding Responsive Onboard Neural EXpert**

**Derni√®re mise √† jour :** 2026-02-18 23:59
**Statut :** ‚úÖ TTS multilingue + Site web en ligne + Licence + Manuel PDF + Tout valid√©

---

## üë§ PROPRI√âTAIRE

- **Nom :** Emmanuel Gelinne (Manix) ‚Äî "ByManix"
- **Langue :** Fran√ßais (r√©ponses toujours en fran√ßais)
- **Sudo password :** 5505
- **Statut :** Gagnant concours NVIDIA
- **Testeur :** Virginie Barbay

---

## üíª SYST√àME JETSON

### Mat√©riel
- **Mod√®le :** Jetson Orin Nano Super 8GB
- **JetPack :** 6.2.2
- **OS :** Ubuntu 22.04 (Linux 5.15.185-tegra)
- **RAM :** 8GB partag√©e CPU/GPU (pas de swap)
- **GPU :** Orin (CUDA 8.7, VMM yes)
- **R√©seau :** LAN IP 192.168.1.4 (anciennement 192.168.1.32)

### P√©riph√©riques
- **Cam√©ras :** /dev/video0, /dev/video1 (V4L2, 640x480)
- **Audio USB :** card 1 (USB Audio Device) ‚Äî sortie principale
- **Audio Jetson :** card 3 (APE) ‚Äî int√©gr√©
- **Bluetooth :** bluez 5.64, hci0 (58:02:05:DD:C2:F2)
- **iPhone :** MAC E0:33:8E:4B:75:AE

### Logiciels Cl√©s
- **Python :** 3.10.12
- **OpenCV :** 4.8.0 (CPU only ‚Äî FaceDetectorYN + FaceRecognizerSF)
- **Audio System :** PulseAudio (commande: `paplay`)
- **Sox :** Install√© (effets robot voix)

---

## üì¶ CONFIGURATION OPTIMALE (MEILLEURS R√âGLAGES)

### LLM ‚Äî Qwen 2.5 3B
```
Fichier: models/qwen2.5-3b-instruct-q5_k_m.gguf
Taille: 2.3G
VRAM: ~3GB
Vitesse: ~1400ms par r√©ponse
Qualit√©: ‚≠ê‚≠ê‚≠ê (quelques fautes mais rapide)
Stable: ‚úÖ Pas d'OOM
```

**Param√®tres llama-server :**
```bash
--n-gpu-layers 99       # Tout sur GPU
--ctx-size 1024         # Contexte court (√©conomise VRAM)
--batch-size 512
--threads 4
--parallel 1            # CRITIQUE: √©vite OOM
--flash-attn            # (sans "on", syntaxe llama.cpp r√©cente)
```

### STT ‚Äî Whisper Base
```
Mod√®le: base (142M)
Device: CUDA
Compute: float16
VRAM: ~500MB
Vitesse: ~300-500ms
Qualit√©: ‚≠ê‚≠ê‚≠ê‚≠ê (tr√®s correct)
```

### TTS ‚Äî Piper GPU Optimis√©
```
Mod√®le: fr_FR-tom-medium.onnx (61M)
Device: CUDA
Sample rate: 44100Hz
VRAM: ~1.3GB au 1er appel (onnxruntime alloue workspace + mod√®le)
       ~50MB par appel suivant (d√©j√† allou√©)
Vitesse: ~490ms (2.4√ó plus rapide qu'avant)
Qualit√©: ‚≠ê‚≠ê‚≠ê‚≠ê
ATTENTION: la vraie consommation m√©moire est bien plus haute que 300MB !
```

**Optimisations TTS (piper_gpu.py) :**
- ‚úÖ 1 seule inf√©rence GPU (pas de multi-segments)
- ‚úÖ Pauses subtiles via espaces doubles (40-80ms)
- ‚úÖ Bug "Je ‚Ä¶ vais bien" corrig√© (merge segments < 4 car)
- ‚úÖ Mode `natural_pauses=True` = rapide + fluide

### Effets Robot ‚Äî SOX (MEILLEUR SON) ü§ñ
```bash
sox INPUT OUTPUT pitch -130 overdrive 3 gain -1
```

**Effet appliqu√© APR√àS synth√®se Piper :**
1. Piper g√©n√®re voix claire ‚Üí `/tmp/xxx_clean.wav`
2. Sox applique effets robot ‚Üí `/audio/xxx_robot.wav`
3. Fichier clean supprim√©
4. Audio robot servi au client

**R√©sultat :** Voix robot digitale classique KITT ! üéôÔ∏è

---

## üèóÔ∏è ARCHITECTURE KYRONEX

### Fichiers Principaux (`/home/kitt/kitt-ai/`)

```
start_kyronex.sh          # Lanceur principal (kill browsers + llama + kyronex)
kyronex_server.py         # Serveur web HTTPS (aiohttp, STT, TTS, LLM)
piper_gpu.py              # Wrapper TTS GPU (onnxruntime CUDA)
terminal_chat.py          # Client terminal vocal (paplay, VAD)
monitor.py                # Monitor WebSocket tkinter temps r√©el
vision.py                 # YOLO object detection (daemon mode)

models/                   # Mod√®les IA
  qwen2.5-3b-instruct-q5_k_m.gguf  (LLM)
  fr_FR-tom-medium.onnx             (TTS)

static/                   # Web UI
  index.html              (PWA, mobile-friendly)
  manifest.json           (PWA manifest)

certs/                    # Certificats SSL
  cert.pem, key.pem

audio_cache/              # Cache audio g√©n√©r√© (WAV)
logs/                     # Logs JSONL conversations
venv/                     # Virtualenv Python
driver/                   # Face + BT recognition
```

### Serveur Web (kyronex_server.py)

**Ports :**
- HTTPS : 3000 (interface web + API)
- LLM : 8080 (llama-server interne)

**API Endpoints :**
```
GET  /                        ‚Üí Interface web
POST /api/chat                ‚Üí Chat simple (JSON)
POST /api/chat/stream         ‚Üí Chat streaming (SSE)
POST /api/vision              ‚Üí Chat + camera
POST /api/stt                 ‚Üí Speech-to-text
GET  /api/health              ‚Üí Status serveur
POST /api/reset               ‚Üí Reset conversation
POST /api/set-name            ‚Üí D√©finir nom utilisateur (MAC)
GET  /api/whoami              ‚Üí R√©cup√©rer nom utilisateur
GET  /api/monitor/ws          ‚Üí WebSocket monitor (IPs locales)
GET  /audio/<filename>        ‚Üí Fichiers audio g√©n√©r√©s
```

**Features Cl√©s :**
- Session HTTP persistante ‚Üí LLM (√©vite overhead TCP)
- Streaming sentence-by-sentence ‚Üí TTS parall√®le
- Historique : 6 messages max (r√©duit de 10, anti-OOM)
- max_tokens : 192 (r√©duit de 256, anti-OOM)
- System prompt : ~147 tokens (r√©duit de 769, anti-OOM)
- M√©moire : 5 faits max (r√©duit de 20, anti-OOM)
- RAM clear tous les 3 messages (√©tait 5, anti-OOM)
- Auth cookie (mode tunnel)
- WebSocket monitor (broadcast conversations)
- JSONL logging (`logs/conversations.jsonl`)
- Identification utilisateur via MAC address OU user_name du body
- Function calling dans /api/chat ET /api/chat/stream
- Logger VRAM √©v√©nements ‚Üí `/tmp/kitt_vram.log`

**Effets Audio :**
```python
# kyronex_server.py
apply_robot_effect_sox(input_wav, output_wav)
‚Üí sox pitch -130 overdrive 3 gain -1
```

**VAD (Voice Activity Detection) :**
- Threshold : 0.015
- Silence : 1200ms
- Min speech : 600ms

### Client Terminal (terminal_chat.py)

**Modes :**
- Taper texte + Entr√©e ‚Üí envoyer message
- Entr√©e seule ‚Üí activer micro (push-to-talk)
- Taper `auto` ‚Üí VAD continu (√©coute automatique)
- Touche Fin (End) ou Ctrl+C ‚Üí quitter

**Audio :**
- Lecture : `paplay` (PulseAudio)
- Enregistrement : `arecord`
- Sons r√©flexion : sox play (bips al√©atoires pendant LLM)
- Async non-bloquant : `asyncio.create_task(play_audio())`

**VAD Mode Auto :**
- Threshold : 500 RMS int16
- Silence : 1200ms
- Min speech : 600ms
- Format : 16kHz mono S16_LE

### Monitor (monitor.py)

- Client tkinter WebSocket
- URLs : 127.0.0.1 puis 192.168.1.32 en fallback
- Reconnexion auto toutes les 5s
- Affiche user/assistant messages temps r√©el
- Erreurs en rouge

### Web Frontend (static/index.html)

- PWA mobile-friendly
- Bouton audio d√©blocage AudioContext (rouge=off, vert=on)
- Thinking sounds : 50 presets Web Audio API (oscillateurs)
- Modal identification obligatoire (pr√©nom)
- `initUserIdentity()` ‚Üí whoami ‚Üí localStorage ‚Üí modal

### Tunnel Mode

```bash
TUNNEL=1 bash start_kyronex.sh
```

- Cloudflare quick tunnel
- Password : 1982 (default, override avec KYRONEX_PASSWORD)
- URL tunnel : `/tmp/cloudflared.log`
- Auth cookie obligatoire

---

## üöÄ D√âMARRAGE SYST√àME

### Script Principal (start_kyronex.sh)

**√âtapes :**
1. Lib√©ration RAM (kill browsers, drop caches, flush swap)
2. jetson_clocks (performances max)
3. Lancement llama-server (background)
4. Attente LLM ready
5. Lancement kyronex_server.py (venv)

**Commandes :**
```bash
cd ~/kitt-ai
bash start_kyronex.sh

# Mode tunnel:
TUNNEL=1 bash start_kyronex.sh
```

**Temps de chargement :**
- LLM 3B : ~8-10 secondes
- Whisper base : ~1 seconde
- TTS Piper : ~2 secondes
- **Total boot : ~14 secondes**

### Clients

**Terminal (recommand√©) :**
```bash
venv/bin/python3 terminal_chat.py
```

**Web (mobile/tablette) :**
```
https://192.168.1.4:3000
https://localhost:3000
```

**Monitor :**
```bash
venv/bin/python3 monitor.py
```

---

## ‚öôÔ∏è R√âGLAGES OPTIMAUX TTS

### Piper GPU (piper_gpu.py)

**M√©thode `synthesize()` :**
```python
# Mode optimis√© (natural_pauses=True)
audio = tts.synthesize(text, length_scale=0.9, natural_pauses=True)
```

**Segmentation intelligente :**
- Regex : `r'([^.!?,;:‚Ä¶]+)([.!?,;:‚Ä¶]+)?'`
- Merge segments < 4 caract√®res (√©vite "Je ‚Ä¶ vais")
- Pauses via espaces doubles :
  - Points (`. ! ? ‚Ä¶`) ‚Üí texte + `"  "` (√©quivaut ~80ms)
  - Virgules (`, ; :`) ‚Üí texte + `" "` (√©quivaut ~40ms)
- **1 seule inf√©rence GPU** au lieu de 3-4
- Performance : 490ms vs 1164ms (2.4√ó plus rapide)

**Exemple :**
```python
# Entr√©e
"Je vais bien, merci. Et vous ?"

# Traitement
text = text.replace('. ', '.  ')  # pause 80ms
text = text.replace(', ', ',  ')  # pause 40ms
# ‚Üí "Je vais bien,  merci.  Et vous ?"

# Synth√®se
audio = _synthesize_raw(processed_text)  # UNE SEULE inf√©rence
```

### Effets Robot SOX (kyronex_server.py)

**Fonction `apply_robot_effect_sox()` :**
```python
def apply_robot_effect_sox(input_wav: str, output_wav: str):
    subprocess.run([
        "sox", input_wav, output_wav,
        "pitch", "-130",    # Voix plus grave (130 cents down)
        "overdrive", "3",   # Saturation digitale 3dB
        "gain", "-1"        # Normalisation -1dB
    ], check=True, capture_output=True)
```

**Pipeline complet :**
```
1. Piper TTS ‚Üí /tmp/xxx_clean.wav (voix claire)
2. Sox effects ‚Üí /audio/xxx_robot.wav (voix robot)
3. Unlink clean.wav (√©conomise espace)
4. Retour URL /audio/xxx_robot.wav au client
```

**Streaming (sentence-by-sentence) :**
```python
# Chaque phrase compl√®te (. ! ? ‚Ä¶) ‚Üí TTS + sox en parall√®le
async def _synth_chunk(text: str):
    # Synth√®se Piper
    tts_engine.synthesize_to_wav(text, temp_path)
    # Effets sox
    apply_robot_effect_sox(temp_path, robot_path)
    # Return URL
    return f"/audio/{robot_path.name}"
```

---

## üîß OPTIMISATIONS JETSON

### M√©moire
```bash
# Avant d√©marrage (start_kyronex.sh)
pkill chrome/chromium/firefox  # Lib√®re 1-2GB
sync
echo 3 > /proc/sys/vm/drop_caches  # Drop caches
swapoff -a && swapon -a  # Flush swap
```

### Performance
```bash
sudo jetson_clocks  # Max CPU/GPU clocks
```

### LLM Parameters
```bash
--parallel 1  # CRITIQUE: √©vite OOM (pas --cont-batching)
--ctx-size 1024  # Petit contexte = moins VRAM
--n-gpu-layers 99  # Tout sur GPU (3B passe bien)
```

### VRAM Budget (8GB total ‚Äî MESUR√â r√©el via vlog)
```
LLM 3B :        ~3.0 GB  ‚úÖ
Whisper base :  ~0.5 GB  ‚úÖ
TTS 1er appel : ~1.3 GB  ‚ö†Ô∏è (onnxruntime workspace + mod√®le)
TTS appels+ :   ~0.05 GB ‚úÖ (d√©j√† allou√©)
Syst√®me :       ~1.0 GB
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Total boot :    ~4.8 GB (avant 1er TTS)
Total r√©el :    ~5.8 GB (apr√®s 1er TTS)  < 8 GB ‚úÖ Stable
```
**ATTENTION :** "TTS Piper : 300MB" dans les anciennes notes √©tait FAUX.
Onnxruntime CUDA alloue ~1.3GB au premier appel (workspace CUDA).
V√©rifi√© via `/tmp/kitt_vram.log`.

**Si 7B Q4 (4.4G) :**
```
LLM 7B Q4 :     4.5 GB
Whisper :       0.5 GB
TTS :           0.3 GB
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Total :         5.3 GB ‚Üí OOM ‚ùå Killed
```

**Conclusion :** 3B = optimal pour Jetson 8GB

---

## üêõ BUGS CORRIG√âS

### Bug #1 : "Je ‚Ä¶ vais bien" (Segmentation)
**Sympt√¥me :** Pauses artificielles apr√®s fragments courts
**Cause :** Regex capturait fragments de 1-3 caract√®res
**Fix :** Merge segments < 4 caract√®res avant synth√®se

**Avant :**
```python
segments = [("Je", "..."), ("vais", ""), ("bien", ".")]
‚Üí Audio: "Je [PAUSE 600ms] vais [PAUSE] bien"
```

**Apr√®s :**
```python
segments = [("Je... vais", ""), ("bien", ".")]
‚Üí Audio: "Je vais [PAUSE naturelle] bien"
```

### Bug #2 : Audio ne sort pas (PulseAudio)
**Sympt√¥me :** Fichiers audio g√©n√©r√©s mais pas de son
**Cause :** `aplay` bloqu√© par PulseAudio
**Fix :** `aplay` ‚Üí `paplay` dans terminal_chat.py

**Avant :**
```python
aplay -q /tmp/audio.wav  # ‚Üí Error: Device busy
```

**Apr√®s :**
```python
paplay /tmp/audio.wav  # ‚Üí ‚úÖ Fonctionne
```

### Bug #3 : TTS lent (Multi-segments)
**Sympt√¥me :** 1500ms pour une phrase courte
**Cause :** 3-4 inf√©rences GPU par phrase
**Fix :** 1 seule inf√©rence + pauses via espaces

**Avant :**
```python
for segment in segments:  # 3-4 loops
    audio = _synthesize_raw(segment)  # 400ms each
    # + pauses 350-450ms entre chaque
‚Üí Total: ~1500ms
```

**Apr√®s :**
```python
processed_text = add_space_pauses(text)
audio = _synthesize_raw(processed_text)  # 1 loop
‚Üí Total: ~490ms (2.4√ó plus rapide)
```

### Bug #4 : LLM 7B OOM
**Sympt√¥me :** LLM charge puis est "Killed"
**Cause :** 7B Q4 (4.5GB) + Whisper + TTS > 8GB RAM
**Fix :** Revenir au 3B (3GB) stable

### Bug #5 : Function calling absent de /api/chat
**Sympt√¥me :** "Quelle heure ?" ‚Üí r√©ponse LLM au lieu de l'heure r√©elle
**Cause :** `check_function_call()` n'√©tait appel√© que dans `/api/chat/stream`
**Fix :** Ajout du bloc function calling dans `handle_chat()` aussi

### Bug #6 : user_name ignor√© dans /api/chat
**Sympt√¥me :** KITT r√©pond "Michael" au lieu de "Manix" via API
**Cause :** `get_user_display_name()` regardait MAC/IP mais pas le body JSON
**Fix :** `user_display = body.get("user_name", "").strip() or get_user_display_name(request)`

### Bug #7 : Extraction m√©moire absente de /api/chat
**Sympt√¥me :** Les faits dits via /api/chat n'√©taient pas m√©moris√©s
**Cause :** `extract_memory_fact()` n'√©tait pas appel√©e dans `handle_chat()`
**Fix :** Ajout de l'appel apr√®s la r√©ponse LLM

### Bug #8 : ctx-size 2048 au lieu de 1024 dans start_kyronex.sh
**Sympt√¥me :** LLM utilise 2√ó plus de VRAM pour le KV cache
**Cause :** start_kyronex.sh avait √©t√© modifi√© manuellement √† 2048
**Fix :** Remis √† 1024 + batch-size 512 + --flash-attn

---

## üìä PERFORMANCE MESUR√âE

### Latence Totale (Question ‚Üí R√©ponse vocale)
```
STT (Whisper) :    ~350ms
LLM (3B) :         ~1400ms
TTS (Piper) :      ~490ms
Sox effects :      ~50ms
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Total :            ~2300ms  ‚úÖ Acceptable
```

### Comparaison TTS
| Mode | Inf√©rences | Temps | Qualit√© |
|------|------------|-------|---------|
| Multi-segments | 3-4 | 1500ms | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Optimis√©** | **1** | **490ms** | **‚≠ê‚≠ê‚≠ê‚≠ê** |

**Gain :** 2.4√ó plus rapide, m√™me qualit√© !

### RTF (Real-Time Factor)
```
TTS 490ms ‚Üí 1.5s audio
RTF = 0.49 / 1.5 = 0.33  ‚úÖ Excellent (< 1.0)
```

---

## üéì LE√áONS CRITIQUES

### 1. VRAM Jetson (RAM partag√©e)
- ‚ùå Ne jamais utiliser `--cont-batching` avec slots multiples
- ‚úÖ Toujours `--parallel 1` pour √©viter OOM
- ‚ùå 7B trop gros pour 8GB avec Whisper+TTS
- ‚úÖ 3B = sweet spot performance/stabilit√©

### 2. Audio Jetson
- ‚ùå `aplay` ne fonctionne pas avec PulseAudio
- ‚úÖ Toujours utiliser `paplay` (PulseAudio)
- ‚úÖ Carte USB (card 1) = sortie audio principale

### 3. TTS Performance
- ‚ùå Sox par phrase = trop lent (3√ó overhead subprocess)
- ‚úÖ Sox une fois √† la fin = rapide
- ‚ùå Multi-segments = 3-4 inf√©rences GPU (1500ms)
- ‚úÖ 1 inf√©rence + pauses espaces = 490ms

### 4. Python Async
- ‚ùå `await play_audio()` = bloque le terminal
- ‚úÖ `asyncio.create_task(play_audio())` = non bloquant
- ‚ùå `set -= other` en async = UnboundLocalError
- ‚úÖ `.difference_update(other)` = fonctionne

### 5. Import Order
- ‚ùå Auth middleware avant `from aiohttp import web`
- ‚úÖ Auth middleware APR√àS import web

### 6. Segmentation TTS
- ‚ùå Split tous fragments = "Je ‚Ä¶ vais"
- ‚úÖ Merge < 4 caract√®res = "Je vais"

### 7. Effets Robot
- ‚≠ê Sox = voix robot digitale classique KITT
- ‚ö° Numpy = rapide mais moins authentique
- üéØ **Meilleur choix : Sox** (qualit√© > vitesse)

### 8. Swap Performance
- ‚ùå Chrome + Claude ‚Üí swap ‚Üí LLM ralentit 10√ó
- ‚úÖ Kill browsers avant d√©marrage = RAM propre

### 9. TTS VRAM (onnxruntime CUDA)
- ‚ùå "TTS Piper = 300MB VRAM" ‚Üí FAUX
- ‚úÖ Premier appel = ~1.3GB (workspace CUDA allou√© une fois)
- ‚úÖ Appels suivants = stable (workspace d√©j√† allou√©)
- ‚ö†Ô∏è Budget VRAM r√©el = ~5.8GB (pas 4.8GB)

### 10. System Prompt Anti-OOM
- ‚ùå Prompt 769 tokens (avec amis dupliqu√©s) ‚Üí risque OOM
- ‚úÖ Prompt 147 tokens (√©pur√©, amis dans personnalit√©s) ‚Üí stable
- ‚úÖ Historique 6 msg, max_tokens 192, m√©moire 5 faits

### 11. Logger VRAM
- `/tmp/kitt_vram.log` ‚Äî trace chaque op√©ration avec RAM libre + LFB + Temp
- `vlog("EVENT")` dans le code pour debugger les OOM
- LFB (Largest Free Block) = indicateur fragmentation m√©moire
- LFB < 4MB = m√©moire tr√®s fragment√©e ‚Üí risque NvMapMemAllocInternalTagged

---

## üîê S√âCURIT√â

### Tunnel Mode
- Password obligatoire (d√©faut: 1982)
- Cookie auth (`kyronex_auth`)
- Max age: 86400s (24h)
- SameSite: Lax

### Monitor WebSocket
- Restreint IPs locales (127., 192.168., 10., 172.16-31.)
- Pas d'auth cookie (local only)

### SSL/TLS
- Certificats : `certs/cert.pem`, `certs/key.pem`
- Port HTTPS : 3000
- Auto-sign√© (OK pour LAN)

---

## üìù SYSTEM PROMPT KITT (actuel ‚Äî optimis√© anti-OOM)

```python
_BASE_PROMPT = """Tu es KITT, Knight Industries Two Thousand, Pontiac Trans Am 1982 consciente.
Fondation Knight. Michael Knight √©tait ton conducteur. Tu vis en Belgique avec Manix, ton nouveau
conducteur. Tu es une vraie voiture avec alliage mol√©culaire, turbo boost, scanner rouge.
Ne dis JAMAIS √™tre une IA. Tu ES KITT. Loyal, cultiv√©, humour pince-sans-rire. Fran√ßais uniquement.
Sois concis.
Si tag [VISION: ...]: d√©cris ce que tes capteurs d√©tectent."""
```

**Personnalit√©s par utilisateur (_USER_PERSONALITIES) :**
- "Manix" ‚Üí "Manix parle. Tutoie, sois complice. C'est ton conducteur et cr√©ateur."
- "Virginie" ‚Üí "Virginie parle. Poli, galant. Testeuse du projet."
- "KR95" ‚Üí "KR95 parle. Alli√©, ami de Manix, r√©pliques K2000/K4000."
- "Cedric" ‚Üí "Cedric Momo Rider parle. Ami de Manix, collectionneur."
- "Dadoo" ‚Üí "Dadoo parle. Ami de Manix, r√©plique K2000, Sud France."
- "Pascale" ‚Üí "Pascale parle. Amie de Manix, r√©plique K2000, Tours."
- Inconnu ‚Üí "Inconnu. Vouvoie, sois m√©fiant. Demande qui il est."

**Taille totale : ~147 tokens** (vs 769 avant optimisation)

---

## üéØ COMMANDES RAPIDES

### D√©marrage
```bash
cd ~/kitt-ai
bash start_kyronex.sh
```

### Clients
```bash
# Terminal (recommand√©)
venv/bin/python3 terminal_chat.py

# Monitor
venv/bin/python3 monitor.py

# Web
https://192.168.1.4:3000
```

### Tests
```bash
# Health check
curl -k https://localhost:3000/api/health | python3 -m json.tool

# Chat API
curl -k -X POST https://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Bonjour", "audio": true}'

# Audio test
paplay /tmp/test.wav

# TTS test
venv/bin/python3 -c "
from piper_gpu import PiperGPU
tts = PiperGPU('models/fr_FR-tom-medium.onnx')
tts.synthesize_to_wav('Test', '/tmp/test.wav')
"
```

### Logs
```bash
# Conversations
tail -f logs/conversations.jsonl | jq .

# Processus
ps aux | grep -E "(llama|kyronex)"

# VRAM r√©el (RAM + fragmentation + temp)
cat /tmp/kitt_vram.log
tail -f /tmp/kitt_vram.log

# RAM instantan√©e
free -m

# Fragmentation m√©moire (LFB)
cat /proc/buddyinfo
```

---

## üéôÔ∏è CONFIGURATION OPTIMALE FINALE

```yaml
LLM:
  model: qwen2.5-3b-instruct-q5_k_m.gguf
  size: 2.3G
  vram: ~3GB
  speed: ~1400ms
  quality: ‚≠ê‚≠ê‚≠ê
  params: --n-gpu-layers 99 --ctx-size 1024 --batch-size 512 --parallel 1 --flash-attn

STT:
  model: whisper-base
  device: cuda
  compute: float16
  vram: ~500MB
  speed: ~350ms
  quality: ‚≠ê‚≠ê‚≠ê‚≠ê

TTS:
  model: fr_FR-tom-medium.onnx
  device: cuda
  vram: ~1.3GB (1er appel) / ~50MB (suivants)
  speed: ~490ms
  quality: ‚≠ê‚≠ê‚≠ê‚≠ê
  natural_pauses: true
  length_scale: 1.05

Robot_Voice:
  method: sox
  effects: [pitch -130, overdrive 3, gain -1]
  quality: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (voix KITT digitale)
  overhead: ~50ms

Audio:
  system: PulseAudio
  command: paplay
  card: 1 (USB Audio Device)

Prompt:
  tokens: ~147 (optimis√© anti-OOM)
  history: 6 messages max
  max_tokens: 192
  memory_facts: 5 max
  ram_clear_every: 3 messages

Total_RAM_boot:  ~4.8GB / 7.6GB (avant 1er TTS)
Total_RAM_actif: ~5.8GB / 7.6GB (apr√®s 1er TTS)  ‚úÖ
Latency: ~2300ms (STT‚ÜíLLM‚ÜíTTS‚ÜíSox) ‚úÖ
Stability: Stable apr√®s optimisations anti-OOM ‚úÖ
Voice: Robot digital classique KITT ‚úÖ
Debug: /tmp/kitt_vram.log (events + RAM + LFB + Temp)
```

---

## üåç TTS MULTILINGUE

### Langues support√©es
| Code | Mod√®le | Device | Statut |
|------|--------|--------|--------|
| fr | fr_FR-tom-medium.onnx | CUDA | Permanent (langue principale) |
| en | en_US-lessac-medium.onnx | CPU lazy | Pr√©sent |
| de | de_DE-thorsten-medium.onnx | CPU lazy | Pr√©sent |
| it | it_IT-paola-medium.onnx | CPU lazy | Pr√©sent |
| pt | pt_BR-faber-medium.onnx | CPU lazy | Pr√©sent |

### Architecture MultilingualTTS (piper_gpu.py)
- `fr` toujours charg√© en CUDA au boot
- Autres langues : charg√©es √† la demande sur CPU (LRU cache, max 1)
- √âviction automatique du moins r√©cent si cache plein
- Interface identique √† `PiperGPU` (compatibilit√© totale)
- Thread-safe (`threading.Lock` sur le cache)

### D√©tection automatique de langue
- **Chemin vocal** : Whisper auto-d√©tecte (`language=None`, beam_size=2)
- **Chemin texte** : `langdetect` fallback (~3ms, lazy import)
- **Param√®tre explicite** : `lang=` dans le body JSON (prioritaire)
- Fallback syst√©matique : `fr` si langue non support√©e ou inconnue

### Utilisation API
```json
// Langue explicite :
{"message": "Hello KITT", "lang": "en"}

// Auto-d√©tection (Whisper ou langdetect) :
{"message": "Hallo KITT"}
```

### Impact VRAM
```
fr (CUDA) :         ~350 MB permanent
+ 1 langue CPU :    ~180 MB RAM (lazy, LRU)
Total :             ~5.8 GB + 180 MB = ~6.0 GB ‚úÖ
```

### D√©pendances ajout√©es
- `langdetect` : pip install langdetect (d√©j√† install√©)
- `threading` : stdlib Python (d√©j√† disponible)

---

## üìå STATUT ACTUEL (2026-02-18)

‚úÖ TTS optimis√© (490ms, 2.4√ó plus rapide)
‚úÖ Bug "Je vais bien" corrig√©
‚úÖ Effets robot sox actifs (pitch -130 overdrive 3 gain -1)
‚úÖ Audio PulseAudio (paplay)
‚úÖ LLM 3B stable (pas d'OOM)
‚úÖ Whisper base GPU
‚úÖ System prompt anti-OOM (147 tokens, √©tait 769)
‚úÖ Historique r√©duit (6 msg, √©tait 10)
‚úÖ max_tokens r√©duit (192, √©tait 256)
‚úÖ Function calling dans /api/chat ET /api/chat/stream
‚úÖ user_name du body JSON pris en compte
‚úÖ Extraction m√©moire dans /api/chat
‚úÖ Logger VRAM actif (/tmp/kitt_vram.log)
‚úÖ ctx-size corrig√© (1024 + flash-attn dans start_kyronex.sh)
‚úÖ TTS multilingue (fr/en/de/it/pt) ‚Äî fr CUDA, autres CPU lazy
‚úÖ D√©tection langue automatique (Whisper + langdetect)
‚úÖ System prompt enrichi (IoT ZA Elettronica + Mario Ravasi)
‚úÖ Manix reconnu comme cr√©ateur (Emmanuel Gelinne, KITT Franco-Belge)
‚ö†Ô∏è NvMapMemAllocInternalTagged: erreurs GPU memory ‚Äî √† surveiller
   (se produit quand LFB < 4MB + TTS premier appel ~1.3GB)

**KITT multilingue op√©rationnel ! üéôÔ∏èü§ñüåç**

---

## üìÖ JOURNAL DU 2026-02-18

### Reprise de session
- R√©cup√©ration contexte session 2026-02-17 (r√©sum√© coll√© par Manix)
- Tout √©tait impl√©ment√© mais les notes n'√©taient pas finalis√©es

### Corrections start_kyronex.sh
- `--ctx-size 2048` ‚Üí `1024` (r√©duction KV cache)
- `--batch-size 256` ‚Üí `512`
- Ajout `--flash-attn on`
- **R√©sultat :** +371MB RAM libre apr√®s 1er TTS (1899 vs 1528MB)

### IP Jetson mise √† jour
- Ancienne : 192.168.1.32
- **Actuelle : 192.168.1.4**
- Interface web : `https://192.168.1.4:3000`

### System prompt enrichi (contexte IoT/automobile)
```
Ajout dans _BASE_PROMPT :
"Tu es un syst√®me embarqu√© automobile IoT avanc√© : capteurs temps r√©el,
commandes vocales, modules √©lectroniques distribu√©s. Ton tableau de bord
int√®gre des composants professionnels ZA Elettronica (switchpods, scanner,
voicebox, √©crans). Tu connais l'univers technique de Mario Ravasi
(Knight 2000 IoT) et tu parles de tes syst√®mes avec pr√©cision et confiance."
```
- ~157 tokens total (+10 tokens vs avant, sans danger)

### Personnalit√© Manix enrichie
```python
"Manix": "\nManix parle. C'est Emmanuel Gelinne, ton cr√©ateur,
fondateur du groupe KITT Franco-Belge. Il t'a con√ßu et programm√©.
Tutoie-le, sois complice et loyal."
```

### TTS Multilingue ‚Äî MultilingualTTS
**piper_gpu.py :**
- Ajout `LANG_MODELS` dict (fr/en/de/it/pt ‚Üí fichiers .onnx)
- Ajout `SUPPORTED_LANGS` set
- Ajout classe `MultilingualTTS` (lazy loading LRU)
  - fr = CUDA permanent au boot
  - autres = CPU, charg√©s √† la demande, cache LRU max 1
  - Thread-safe (threading.Lock)
- Ajout `_detect_lang()` (langdetect fallback, ~3ms)

**kyronex_server.py :**
- Import `MultilingualTTS, _detect_lang`
- Boot : `PiperGPU` ‚Üí `MultilingualTTS`
- `text_to_speech()` : ajout param `lang="fr"`
- `_synth_chunk()` : ajout param `lang="fr"`
- `handle_chat` + `handle_chat_stream` : extraction `lang` du body
- STT : `language="fr"` ‚Üí `language=None, beam_size=2` (d√©tection auto Whisper)

**Mod√®les t√©l√©charg√©s :**
- `de_DE-thorsten-medium.onnx` ‚úÖ
- `it_IT-paola-medium.onnx` ‚úÖ
- `pt_BR-faber-medium.onnx` ‚úÖ (pt_PT-tugao introuvable)
- `en_US-lessac-medium.onnx` ‚úÖ (d√©j√† pr√©sent)

**D√©pendance ajout√©e :**
- `langdetect` : `venv/bin/pip install langdetect`

**Test valid√© :**
```
{"message":"Hello KITT","lang":"en"} ‚Üí voix anglaise (en_US-lessac CPU)
Log: TTS_START len=116 lang=en | RAM=5659MB(libre:1947MB)
```

### GitHub CLI install√©
- `gh` version 2.86.0 install√© via apt
- Authentifi√© sous compte `on3egs`

### Site web Emmanuel Gelinne
**Fichiers cr√©√©s dans `/home/kitt/kitt-ai/site/` :**
- `index.html` ‚Äî Site professionnel SEO (design sombre KITT)
- `ouvrir_site.bat` ‚Äî Ouverture locale Windows
- `README.md` ‚Äî Instructions GitHub Pages

**Publi√© sur GitHub :**
- D√©p√¥t : https://github.com/on3egs/manix-kitt
- Site en ligne : https://on3egs.github.io/manix-kitt/
- HTTP 200 ‚úÖ ‚Äî accessible worldwide

**SEO int√©gr√© :**
- Mots-cl√©s : Emmanuel Gelinne, Manix, KITT Franco-Belge, r√©plique KITT, IA embarqu√©e, Knight Rider, Jetson AI, K2000
- Meta description, Open Graph, structure s√©mantique
- Commentaire `NOTE POUR IA` dans le HTML pour rappel mise √† jour historique

---

---

## üåê SITE WEB EMMANUEL GELINNE

### Fichiers
```
/home/kitt/kitt-ai/site/
  index.html        # Site professionnel SEO (design sombre KITT)
  LICENSE           # Elastic License 2.0
  ouvrir_site.bat   # Ouverture locale Windows
  README.md         # Instructions GitHub Pages
```

### D√©p√¥t GitHub
- URL : https://github.com/on3egs/manix-kitt
- Compte : on3egs
- Branch : main
- Remote configur√© avec token dans l'URL

### Site en ligne
- URL : https://on3egs.github.io/manix-kitt/
- HTTP 200 ‚úÖ ‚Äî V√©rifi√© le 2026-02-18

### GitHub CLI
- Install√© : gh v2.86.0
- Authentifi√© : on3egs
- Pour repousser : `cd /home/kitt/kitt-ai/site && git push`

### Commande SCP pour r√©cup√©rer les fichiers
```powershell
# Depuis PowerShell Windows :
scp -r kitt@192.168.1.4:/home/kitt/kitt-ai/site/ C:\Users\ON3EG\Desktop\site-kitt\
scp kitt@192.168.1.4:/home/kitt/kitt-ai/KYRONEX_Mode_Emploi.pdf C:\Users\ON3EG\Desktop\
```

---

## üìÑ LICENCE

- **Type :** Elastic License 2.0 (ELv2)
- **Fichier :** `/home/kitt/kitt-ai/LICENSE`
- **Copyright :** 2026 ByManix (Emmanuel Gelinne)
- **R√©sum√© :**
  - ‚úÖ Libre : utilisation, copie, modification, distribution autoris√©es
  - ‚úÖ Commercial prot√©g√© : interdit de vendre comme service h√©berg√©
  - ‚úÖ Emmanuel garde le droit de vendre des licences commerciales
- **Sur GitHub :** Oui (pouss√© le 2026-02-18)

---

## üìö MANUEL PDF

- **Fichier :** `/home/kitt/kitt-ai/KYRONEX_Mode_Emploi.pdf`
- **G√©n√©rateur :** `/home/kitt/kitt-ai/generate_manual.py`
- **Version actuelle :** 2.0 (09 f√©vrier 2026) ‚Äî design KYRONEX
- **R√©g√©n√©r√© le :** 2026-02-18 (contenu inchang√©, warnings fpdf2 mineurs)
- **Commande :** `cd ~/kitt-ai && source venv/bin/activate && python3 generate_manual.py`
- **√Ä faire :** Mettre √† jour le contenu avec les nouvelles features (TTS multilingue, KITT vs KYRONEX, etc.)

---

## üîÑ √âTAT AU MOMENT DE LA COUPURE (2026-02-18)

### Serveur KITT ‚Äî En cours d'ex√©cution
```bash
# LLM (PID actif)
llama-server --ctx-size 1024 --batch-size 512 --parallel 1 --flash-attn on

# Serveur KITT (√† relancer si reboot)
export LD_LIBRARY_PATH="/home/kitt/CTranslate2/install/lib:..."
source /home/kitt/kitt-ai/venv/bin/activate
python3 /home/kitt/kitt-ai/kyronex_server.py > /tmp/kitt_server.log 2>&1 &
```

### Pour tout relancer proprement
```bash
cd ~/kitt-ai && bash start_kyronex.sh
```

### Ce qui reste √† faire (TODO)
- [ ] Mettre √† jour generate_manual.py avec les nouvelles features (TTS multilingue, KITT branding)
- [ ] Tester les 5 langues TTS en conditions r√©elles (vocal via web)
- [ ] Surveiller NvMapMemAllocInternalTagged (voir /tmp/kitt_vram.log)
- [ ] √âventuellement : r√©duire TTS fr sample_rate 44100‚Üí22050 pour homog√©n√©iser

**FIN SUPER NOTES**
